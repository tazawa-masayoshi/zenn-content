---
title: "大速度時代が来た。Cerebras × GLM-4.7が気になる"
emoji: "⚡"
type: "tech"
topics: ["cerebras", "opencode", "ai", "llm", "glm"]
published: false
---

## はじめに

> 業務自動化Pythonエンジニア。バイブコーディング歴1年 ≒ エンジニア歴。

### 「エージェント向け」、みんな同じこと言ってない？

コード生成、ツール駆動型エージェント、マルチターン推論に特化。

最近のLLM、みんなこう言ってる。

正直、LLMのモデル自体はもうそんなに大きく変わらないと思ってる。インターネットに繋がって同じ知識ソースを得て、ClaudeやChatGPTが売れてるからそこを目指して...進化はすごいけど、**Claudeさえ使ってあとはハーネス次第**だと思ってた。

### でもWindsurfのswe-1.5には驚いた

去年の9月、Windsurfが出してきた**速度特化モデル**。あれは確かに速かった。

友人（AIマン）は「バイブが追いつかない」と言ってお気に入りにしてた。

でも私は結局使わなかった。**右チャットアレルギー**が出てしまったし、ターミナル操作が下手だし。うーんって感じだった。

### ハーネスが弱いと使えない

Claude Codeに慣れた**ぬるま湯開発マン**としては、どうしてもハーネスが大事。

ファイル操作、Git連携、MCP、エージェント機構...これらが揃った環境じゃないと、いくら速くても実用にならない。

### そんな時、OpenCodeが面白そうだと気づいた

OpenCodeはCerebras対応してる。

つまり、**使い慣れたハーネスのまま、爆速モデルを試せる**。

**Claude信者卒業か？**

...とまでは言わないけど、ちょっと試してみたくなった。

## Cerebrasとは

### GPUじゃない。WSE（Wafer Scale Engine）

NVIDIAはシリコンウェハーから小さなダイを切り出してGPUを作る。

Cerebrasは違う。**ウェハー全体を1つの巨大チップにする**。

| 項目 | NVIDIA GPU | Cerebras WSE-3 |
|------|-----------|----------------|
| チップサイズ | 切手サイズ以下 | ディナープレートサイズ |
| メモリ | 外部HBM | オンチップSRAM 44GB |
| メモリ帯域幅 | 約3TB/s | **21PB/s**（約7,000倍） |

なぜ速いのか？**データがチップの外に出なくていい**から。

GPUだとデータを外部メモリに出し入れするボトルネックがある。WSEはメモリがチップ上にあるから、その往復がない。

### 分散システムのコードがいらない

通常、大規模モデルを動かすには数千のGPUをネットワークで繋いで、数万行の分散システムコードが必要。

WSEは単一の論理デバイスとして動く。**グルーコードがいらない**。

## GLM-4.7とは

Z.aiから発表された最新モデル。

**スペック：**
- 355Bパラメータ（アクティブ32B）
- MITライセンス
- 開発者ベンチマーク（SWEbench、LiveCodeBench）でDeepSeek-V3.2を上回る

**特徴：**
- **インターリーブド思考**: 各アクション前に推論を実施
- **保持型思考**: 推論コンテキストがターン間で保持される
- **日本語も得意**: オープンモデルの中でもトップクラス

### Thinkingが長すぎる問題

きしださんの記事によると、GLM-4.7は**簡単な質問でもThinkingが長い**らしい。

> ディレクトリを消すコマンドを聞くのに40秒というのは長すぎますね。

答えは最初から出てるのに、どう提示するかを延々と考えてしまう。ここは注意点。

## GLM-4.7を使う方法

### 選択肢

| 方法 | 速度 | コスト | 備考 |
|------|------|--------|------|
| **OpenCode Zen版** | 普通 | 無料 | アカウント登録不要 |
| **Cerebras API** | 爆速 | 従量課金 | 1,000 tok/s |
| **ローカル** | 遅い | 90万円〜 | Mac Studio 256GB必要 |

### OpenCode Zen版（無料）

きしださんが詳しく書いてる。

1. `opencode`コマンドで起動
2. `/models`で「GLM-4.7 OpenCode Zen」を選択
3. 無料で使える

参考: [OpenCodeとGLM 4.7で無課金コーディングエージェント体験](https://nowokay.hatenablog.com/entry/2024/12/29/opencode_glm47)

### Cerebras API経由（爆速）

OpenCodeはCerebrasを公式サポートしてる。

1. [Cerebras Cloud](https://cloud.cerebras.ai/)で**無料のAPIキー**を取得
2. `opencode auth login` を実行
3. プロバイダー選択で「Cerebras」を選ぶ
4. APIキーを入力
5. `/models` でモデル選択

参考: [Cerebras公式 - OpenCode連携ガイド](https://inference-docs.cerebras.ai/integrations/opencode)

## Cerebrasの料金体系

ここがややこしい。

| プラン | 月額 | 内容 |
|--------|------|------|
| **Free** | $0 | レート制限あり |
| **Developer** | $10〜 | + 従量課金 |
| **Pro** | $50 | 2400万tok/日まで |
| **Max** | $200 | 1.2億tok/日まで |

**Developer tierの従量課金例：**
- Llama 3.3 70B: 入力$0.85/M、出力$1.20/M
- Qwen 3 32B: 入力$0.40/M、出力$0.80/M

### Pro/Maxは実質使い放題

2400万tok/日ってどのくらい？

| 作業内容 | 1回のトークン量 | 1日で何回できる |
|----------|----------------|-----------------|
| 軽い質問・修正 | 5,000〜10,000 | 2,400〜4,800回 |
| 機能追加 | 30,000〜50,000 | 480〜800回 |
| 新規プロジェクト生成 | 100,000〜300,000 | 80〜240回 |

**ヘビーに使っても使い切れないレベル**。$50/月で実質使い放題に近い。

### 注意：Cerebras Code vs OpenCode

ただし、Pro/Maxは**Cerebras Code**（Cerebras独自のコーディングツール）の料金。

OpenCode経由で使う場合はDeveloper tier（従量課金）になる可能性がある。**ここは要検証**。

## なぜOpenCode/Claude Codeで使いたいのか

### ハーネスの重要性

コーディングエージェントは「モデルの賢さ」だけじゃない。

- ファイル操作
- Git/jj連携
- MCP統合
- エージェント機構（並列実行、サブエージェント）
- ルールファイル（CLAUDE.md等）

これらの**ハーネスが揃ってないと、実用にならない**。

### 使い慣れた環境で速いモデルを

私の環境：
- Claude Code: メイン（oh-my-opencode入り）
- OpenCode: サブ（Sisyphus、Oracle等のエージェント構成）
- jj: バージョン管理
- Zed + WezTerm: エディタ＋ターミナル

この環境のまま、モデルだけGLM-4.7に切り替えられるなら最高。

## 今後の検証予定

1. **OpenCode経由でCerebras APIを叩いたときの料金体系**
2. **速度の体感比較**（Claude Sonnet vs GLM-4.7）
3. **日本語でのコード生成品質**
4. **Thinkingの長さが実際どのくらい気になるか**

検証したら追記します。

## まとめ

| モデル | 速度 | 用途 |
|-------|------|------|
| Claude Opus 4.5 | 遅い | 複雑な推論 |
| Claude Sonnet 4.5 | 普通 | バランス |
| **GLM-4.7** | 爆速 | スピード重視のタスク |

大速度時代が来てる。

でも大事なのは**ハーネスの中で使えるかどうか**。速いモデルが出ても、使い慣れた環境で動かせなければ意味がない。

OpenCodeがCerebras対応してるのは朗報。検証が楽しみ。

## 参考リンク

- [GLM-4.7 - Cerebras公式ブログ](https://www.cerebras.ai/blog/glm-4-7)
- [GLM-4.7で自宅コーディングエージェントが現実的に - きしだのHatena](https://nowokay.hatenablog.com/entry/2025/01/06/glm47)
- [OpenCodeとGLM 4.7で無課金コーディングエージェント体験 - きしだのHatena](https://nowokay.hatenablog.com/entry/2024/12/29/opencode_glm47)
- [OpenCode 公式](https://opencode.ai/)
- [Cerebras 公式](https://www.cerebras.ai/)

---
title: "LFM 2.5を試してみた。731MBの日本語特化LLMが面白い"
emoji: "🤖"
type: "tech"
topics: ["llm", "ai", "liquidai", "ローカルLLM"]
published: false
---

## はじめに

> 業務自動化Pythonエンジニア。バイブコーディング歴1年 ≒ エンジニア歴。

### 超小型LLMが出た

Liquid AIという無名のAI企業から、**LFM 2.5**というモデルが公開された。

**特徴：**
- 1.2Bパラメータ（超小型）
- 量子化後のサイズ：**731MB**
- 日本語特化モデル「LFM2.5-JP」もある
- スマホでも動く

731MBってことは、普通のアプリくらいのサイズ。**これ、アプリに組み込めるんじゃない？**

### アプリに入れたら面白そうと思った

API料金を気にしなくていい。APIキーをアプリに埋め込む心配もない。

今作ってる個人用ダイエットアプリとか、自分専用のAI秘書とか、バンバン入れ込めるんじゃ？

...と思ったんだけど。

### Claudeに現実を教えられた

「アプリにLLM組み込むのどう思う？」と聞いたら：

- **容量問題**: 731MBでもアプリとしては巨大
- **著作権**: モデルのライセンス確認が必要
- **アプリストア**: AIモデルをそのまま入れたアプリは弾かれる可能性

**時代はまったく来ていなかった。**

### でも個人用なら関係ない

アプリストアに出すわけじゃない。自分用なら問題ない。

というわけで、とりあえず試してみることにした。

## LFM 2.5とは

Liquid AIが2025年1月5日に公開した小型LLMシリーズ。

**ラインナップ：**
| モデル | サイズ | 用途 |
|--------|--------|------|
| LFM2.5-1.2B-Base | 1.2B | ベースモデル |
| LFM2.5-1.2B-Instruct | 1.2B | 追加学習済み |
| **LFM2.5-1.2B-JP** | 1.2B | 日本語特化 |
| LFM2.5-VL-1.6B | 1.6B | 視覚言語モデル |
| LFM2.5-Audio-1.5B | 1.5B | 音声言語モデル |

**日本語特化モデルだけが用意されてる**のが面白い。他の言語はない。

### 性能

- 日本語ベンチマーク「Iza Task 100」で従来モデル（31B）を8%上回る
- N100プロセッサ（2万円ミニPC）でも動く
- Galaxy S25 Ultraで71トークン/秒

小さいのに速い。

## ダウンロードしてみた

とりあえずMac上でチャットできるようにしてみた。

![ローカルLLMチャット](/images/lfm25-chat.png)

シンプルなWebインターフェースで動かしてる。

### 動作環境

<!-- TODO: 自分の環境を書く -->

### 日本語での応答

普通の質問にはちゃんと答える。

> あなた: ローカルLLMってどうなっているの？
>
> AI: ローカルLLMは、ローカルサーバー上で動作する大規模言語モデルです。データをローカルに保持することで、プライバシーとセキュリティを確保しつつ、推論やファインチューニングを高速に行うことができます。

おお、いい感じ。

> あなた: ファインチューニングってどうやったらいいの？
>
> AI: ファインチューニングは、事前学習済みモデルを特定のタスクに適応させるプロセスです。以下のステップで実施します：

途中で切れた。「続きをどうぞ」と言ってみたら...

> AI: わかりました。以下は、ユーザーが「ユーザーが『ユーザーが『ユーザーが『ユーザーが『ユーザーが...

![壊れたLFM2.5](/images/lfm25-broken.png)

**あーあ壊れちゃった僕のおもちゃ❤︎**

小型LLMの限界を感じた瞬間だった。

### 速度

**バカ早い。**

壊れるのも早かった。

## 何に使えそうか

### 個人用アプリ

- ダイエットアプリのアドバイス機能
- 自分専用AI秘書
- メモアプリの要約機能

API料金を気にしなくていいのは大きい。

### ローカル環境での実験

クラウドに送りたくないデータを扱うときに便利そう。

### AI秘書を作るなら

本格的にAI秘書を作るなら、こういう技術が必要になりそう：

- **RAG**: ドキュメント検索+生成
- **LangChain**: 複数LLMのチェーン、ツール使用の管理
- **Function Calling**: 外部APIとの連携

difyやBedrock AgentCoreでチャットボットは作ったことあるけど、ローカルLLMでここまでやれたらめっちゃ面白そう。

LangChainを勉強しようとして本を買ったが途中で止まっている。読まねば。

## まとめ

**まだ実験的な域を出ない。でもめっちゃ面白い。**

アプリに組み込む夢は一旦保留だけど、個人用途では十分遊べる。

AWSのSageMakerとか、こういう小型LLMをエッジデバイスで動かす方向に進んでいくのかな？

731MBで日本語特化LLMが動く。この方向性、もっと進化してほしい。

## 参考リンク

- [Introducing LFM2.5 - Liquid AI](https://www.liquid.ai/blog/introducing-lfm2-5-the-next-generation-of-on-device-ai)
- [LFM2.5-1.2B-JP - Hugging Face](https://huggingface.co/LiquidAI/LFM2.5-1.2B-JP)
- [LFM2.5-1.2B-Instruct - Hugging Face](https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct)

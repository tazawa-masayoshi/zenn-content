---
title: "超小型日本語LLM LFM 2.5-JPと会話してみた"
emoji: "🤖"
type: "tech"
topics: ["llm", "ai", "liquidai", "ローカルLLM"]
published: true
---

## はじめに

> 業務自動化Pythonエンジニア。バイブコーディング歴1年 ≒ エンジニア歴。

### 超小型LLMが出たらしい

YouTubeでこの動画を見た。

https://www.youtube.com/watch?v=nwC4Ky0QL-k

Liquid AIという初めて聞いたAI企業から、**LFM 2.5**というモデルが公開されたらしい。

**特徴：**
- 1.2Bパラメータ（超小型）
- モデルサイズ：**731MB**
- 日本語特化モデル「LFM2.5-JP」もある
- スマホでも動く

731MBってことは、普通のアプリくらいのサイズ。**これ、アプリに組み込めるんじゃない？**

### アプリに入れたら面白そうと思った

API料金を気にしなくていい。APIキーをアプリに埋め込む心配もない。

今作ってる個人用ダイエットアプリとか、自分専用のAI秘書とか、バンバン入れ込めるんじゃ？

...と思ったんだけど。

### Claudeに現実を教えられた

「アプリにLLM組み込むのどう思う？」と聞いたら：

- **容量問題**: 731MBでもアプリとしては巨大
- **著作権**: モデルのライセンス確認が必要
- **アプリストア**: AIモデルをそのまま入れたアプリは弾かれる可能性

まあそりゃそうか。

### でも個人用なら関係ない

アプリストアに出すわけじゃない。自分用なら問題ない。

というわけで、とりあえず試してみることにした。

## LFM 2.5とは

Liquid AIが2025年1月5日に公開した小型LLMシリーズ。

**ラインナップ：**
| モデル | サイズ | 用途 |
|--------|--------|------|
| LFM2.5-1.2B-Base | 1.2B | ベースモデル |
| LFM2.5-1.2B-Instruct | 1.2B | 追加学習済み |
| **LFM2.5-1.2B-JP** | 1.2B | 日本語特化 |
| LFM2.5-VL-1.6B | 1.6B | 視覚言語モデル |
| LFM2.5-Audio-1.5B | 1.5B | 音声言語モデル |

**日本語特化モデルだけが用意されてる**のが面白い。他の言語はない。

### 性能

- 日本語ベンチマーク「Iza Task 100」で従来モデル（31B）を8%上回る
- N100プロセッサ（2万円ミニPC）でも動く
- Galaxy S25 Ultraで71トークン/秒

小さいのに速い。

専用のGPUサーバーじゃなくて、普段のEC2にそのまま入れても動くのでは？

- ただし推論エンジンが変わる：mlx-lmはApple Silicon専用。EC2ではllama-cpp-pythonやvLLMを使う
- 速度は落ちる：GPUなしCPU推論だと遅くなる

## ダウンロードしてみた

とりあえずMac上でチャットできるようにしてみた。

実際にダウンロードしたら**2.2GB**だった。731MBは量子化版の話だったらしい。

![ローカルLLMチャット](/images/lfm25-chat.png)

シンプルなWebインターフェースで動かしてる。

### 動作環境

- MacBook Pro M4 Pro / 48GB RAM
- mlx-lm（Apple Silicon向け推論エンジン）
- FastAPI + Uvicornでローカルサーバー化

### 日本語での応答

普通の質問にはちゃんと答える。

> あなた: ローカルLLMってどうなっているの？
>
> AI: ローカルLLMは、ローカルサーバー上で動作する大規模言語モデルです。データをローカルに保持することで、プライバシーとセキュリティを確保しつつ、推論やファインチューニングを高速に行うことができます。

おお、いい感じ。

> あなた: ファインチューニングってどうやったらいいの？
>
> AI: ファインチューニングは、事前学習済みモデルを特定のタスクに適応させるプロセスです。以下のステップで実施します：

途中で切れた。「続きをどうぞ」と言ってみたら...

> AI: わかりました。以下は、ユーザーが「ユーザーが『ユーザーが『ユーザーが『ユーザーが『ユーザーが...

![壊れたLFM2.5](/images/lfm25-broken.png)

**あーあ壊れちゃった僕のおもちゃ❤︎**

### 速度

**バカ早い。**

壊れるのも早かった。

## 何に使えそうか

### 個人用アプリ

- ダイエットアプリのアドバイス機能
- 自分専用AI秘書
- メモアプリの要約機能

API料金を気にしなくていいのは大きい。

### ローカル環境での実験

クラウドに送りたくないデータを扱うときに便利そう。

### AI秘書を作るなら

本格的にAI秘書を作るなら、LangChainが必要になりそう：

- RAG（ドキュメント検索+生成）
- 複数LLMのチェーン
- ツール使用（Function Calling）の管理
- 複雑なプロンプトテンプレート

difyやBedrock AgentCoreでチャットボットは作ったことあるけど、ローカルLLMでここまでやれたらめっちゃ面白そう。

LangChainを勉強しようとして本を買ったが途中で止まっている。読まねば。

## まとめ

**まだ実験的な域を出ない。でもめっちゃ面白い。**

アプリに組み込む夢は一旦保留だけど、個人用途では十分遊べる。

今年はAIを使う側じゃなくて、AWS SageMakerとかで本格的にAIと向き合うようになっていけたらいいな。

さて次の玩具探さなきゃ。Ollamaのダウンロードを始めました。

## 参考リンク

- [Introducing LFM2.5 - Liquid AI](https://www.liquid.ai/blog/introducing-lfm2-5-the-next-generation-of-on-device-ai)
- [LFM2.5-1.2B-JP - Hugging Face](https://huggingface.co/LiquidAI/LFM2.5-1.2B-JP)
- [LFM2.5-1.2B-Instruct - Hugging Face](https://huggingface.co/LiquidAI/LFM2.5-1.2B-Instruct)
